{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# House Prices - Advanced Regression Techniques\nPredict sales prices and practice feature engineering, RFs, and gradient boosting\n\n## Introduction\n\n>\"In God we trust. All others must bring data.\" â€“ **W. Edwards Deming**\n\nIn today's fiercely competitive real estate market, pinpointing house prices with precision is vital for buyers, sellers, and investors alike. The Kaggle competition \"House Prices - Advanced Regression Techniques\" offers a comprehensive dataset of housing attributes, challenging data scientists to build robust models for predicting property sale prices. By employing sophisticated regression methods and innovative feature engineering, we strive to reveal the patterns and elements that drive house prices. This analysis walks you through a systematic process, from data preprocessing to model evaluation, ultimately empowering us to make well-informed predictions and gain valuable insights into the housing market.\n\n## Approach\n\n#### 1. Basic Data Exploration\n- Import the data\n- Look at the summary statistics\n- Evaluate Null Values\n- Basic Data Exploration\n\n#### 2. Data Preprocessing\n**a. Handle Missing Values:**\n- Identify columns with missing values.\n- Impute missing numerical values with the median.\n- Impute missing categorical values with 'None'.\n\n**b. Encode Categorical Variables:**\n-  Apply one-hot encoding for nominal categorical variables.\n- Normalize/Standardize Numerical Features:\n- Standardize numerical features to have a mean of 0 and a standard deviation of 1.\n\n#### 3. Exploratory Data Analysis (EDA)\n**a. Visualize Distributions and Relationships:**\n- Create histograms, box plots, and scatter plots for numerical variables.\n- Use bar plots for categorical variables.\n\n**b. Correlation Analysis:**\n- Compute and visualize the correlation matrix using a heatmap to uncover relationships between numerical features.\n\n**c. Analyze the Target Variable (SalePrice):**\n- Examine the distribution of SalePrice and apply a log transformation to address skewness.\n\n#### 4. Feature Engineering\n**a. Create New Features:**\n- TotalHouseArea: Combine above-ground living area (GrLivArea) and basement area (TotalBsmtSF).\n- TotalBathrooms: Sum up all full and half bathrooms across different levels.\n- HouseAge: Calculate the difference between the year sold (YrSold) and the year built (YearBuilt).\n- RemodelAge: Calculate the difference between the year sold (YrSold) and the year of the last remodel (YearRemodAdd).\n\n**b. Handle Interaction Terms:**\n- Consider interaction terms between features that may collectively influence SalePrice.\n\n**c. Feature Selection:**\n- Use tree-based feature importance to identify the most relevant features.\n\n#### 5. Model Building\n**a. Split Data:**\n- Divide the dataset into training and validation sets, typically handled during cross-validation.\n\n**b. Train Multiple Models:**\n- Train a variety of models including Linear Regression, Random Forest, and Gradient Boosting Machines (GBM).\n\n**c. Hyperparameter Tuning:**\n- Use default hyperparameters for initial evaluations.\n\n#### 6. Model Evaluation\n**a. Evaluate Model Performance:**\n- Use RMSE to assess model performance and perform cross-validation to ensure stability.\n\n**b. Model Interpretation:**\n- Analyze feature importance, particularly for tree-based models.\n\n**c. Ensemble Methods:**\n- Select the best-performing model (Gradient Boosting Regressor) based on RMSE.\n\n#### 7. Submission\n\n**a. Prepare Test Data:**\n- Apply the same preprocessing and feature engineering steps to the test data.\n\n**b. Generate Predictions:**\n- Use the trained Gradient Boosting Regressor to make predictions on the test data.\n\n**c. Create Submission File:**\n- Format the predictions as required by the Kaggle competition and prepare the submission file.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-25T21:57:31.600998Z","iopub.execute_input":"2024-06-25T21:57:31.601366Z","iopub.status.idle":"2024-06-25T21:57:34.455242Z","shell.execute_reply.started":"2024-06-25T21:57:31.601335Z","shell.execute_reply":"2024-06-25T21:57:34.454109Z"}}},{"cell_type":"markdown","source":">Notebook inspiration [Housing Prices Example](https://www.kaggle.com/code/kenjee/housing-prices-example-with-video-walkthrough)","metadata":{}},{"cell_type":"markdown","source":"## Prerequisites\nHere is the comprehensive list of imports used in the analysis:","metadata":{}},{"cell_type":"code","source":"!pip install -U kaleido","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import relevant packages \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error\nfrom IPython.display import display, HTML","metadata":{"execution":{"iopub.status.busy":"2024-07-12T00:07:56.753917Z","iopub.execute_input":"2024-07-12T00:07:56.754464Z","iopub.status.idle":"2024-07-12T00:07:58.327706Z","shell.execute_reply.started":"2024-07-12T00:07:56.754422Z","shell.execute_reply":"2024-07-12T00:07:58.326583Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### 1. Basic Data Exploration","metadata":{}},{"cell_type":"code","source":"# Load datasets\ntrain_df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\n\n# Display the first few rows of the training dataset\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-12T00:08:02.765815Z","iopub.execute_input":"2024-07-12T00:08:02.767359Z","iopub.status.idle":"2024-07-12T00:08:02.824609Z","shell.execute_reply.started":"2024-07-12T00:08:02.767306Z","shell.execute_reply":"2024-07-12T00:08:02.823124Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n\n  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n\n  YrSold  SaleType  SaleCondition  SalePrice  \n0   2008        WD         Normal     208500  \n1   2007        WD         Normal     181500  \n2   2008        WD         Normal     223500  \n3   2006        WD        Abnorml     140000  \n4   2008        WD         Normal     250000  \n\n[5 rows x 81 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>250000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 81 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-12T00:08:06.102380Z","iopub.execute_input":"2024-07-12T00:08:06.102907Z","iopub.status.idle":"2024-07-12T00:08:06.112546Z","shell.execute_reply.started":"2024-07-12T00:08:06.102868Z","shell.execute_reply":"2024-07-12T00:08:06.110949Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(1460, 81)"},"metadata":{}}]},{"cell_type":"code","source":"# Function to create scrollable table within a small window\ndef create_scrollable_table(df, table_id, title):\n    html = f'<h3>{title}</h3>'\n    html += f'<div id=\"{table_id}\" style=\"height:200px; overflow:auto;\">'\n    html += df.to_html()\n    html += '</div>'\n    return html","metadata":{"execution":{"iopub.status.busy":"2024-07-12T00:08:07.648628Z","iopub.execute_input":"2024-07-12T00:08:07.649111Z","iopub.status.idle":"2024-07-12T00:08:07.657111Z","shell.execute_reply.started":"2024-07-12T00:08:07.649069Z","shell.execute_reply":"2024-07-12T00:08:07.655419Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### 1.1 Numerical Data","metadata":{}},{"cell_type":"code","source":"numerical_features = train_df.select_dtypes(include=[np.number])\nnumerical_features.describe()","metadata":{"execution":{"iopub.status.busy":"2024-07-12T00:08:15.735724Z","iopub.execute_input":"2024-07-12T00:08:15.736306Z","iopub.status.idle":"2024-07-12T00:08:15.836101Z","shell.execute_reply.started":"2024-07-12T00:08:15.736262Z","shell.execute_reply":"2024-07-12T00:08:15.834683Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\ncount  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \nmean    730.500000    56.897260    70.049958   10516.828082     6.099315   \nstd     421.610009    42.300571    24.284752    9981.264932     1.382997   \nmin       1.000000    20.000000    21.000000    1300.000000     1.000000   \n25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \nmax    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n\n       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\ncount  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \nmean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \nstd       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \nmin       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \nmax       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n\n        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\ncount  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \nmean     94.244521    46.660274      21.954110     3.409589    15.060959   \nstd     125.338794    66.256028      61.119149    29.317331    55.757415   \nmin       0.000000     0.000000       0.000000     0.000000     0.000000   \n25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n75%     168.000000    68.000000       0.000000     0.000000     0.000000   \nmax     857.000000   547.000000     552.000000   508.000000   480.000000   \n\n          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \ncount  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \nmean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \nstd      40.177307    496.123024     2.703626     1.328095   79442.502883  \nmin       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \nmax     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n\n[8 rows x 38 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>MasVnrArea</th>\n      <th>BsmtFinSF1</th>\n      <th>...</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1201.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1452.000000</td>\n      <td>1460.000000</td>\n      <td>...</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>730.500000</td>\n      <td>56.897260</td>\n      <td>70.049958</td>\n      <td>10516.828082</td>\n      <td>6.099315</td>\n      <td>5.575342</td>\n      <td>1971.267808</td>\n      <td>1984.865753</td>\n      <td>103.685262</td>\n      <td>443.639726</td>\n      <td>...</td>\n      <td>94.244521</td>\n      <td>46.660274</td>\n      <td>21.954110</td>\n      <td>3.409589</td>\n      <td>15.060959</td>\n      <td>2.758904</td>\n      <td>43.489041</td>\n      <td>6.321918</td>\n      <td>2007.815753</td>\n      <td>180921.195890</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>421.610009</td>\n      <td>42.300571</td>\n      <td>24.284752</td>\n      <td>9981.264932</td>\n      <td>1.382997</td>\n      <td>1.112799</td>\n      <td>30.202904</td>\n      <td>20.645407</td>\n      <td>181.066207</td>\n      <td>456.098091</td>\n      <td>...</td>\n      <td>125.338794</td>\n      <td>66.256028</td>\n      <td>61.119149</td>\n      <td>29.317331</td>\n      <td>55.757415</td>\n      <td>40.177307</td>\n      <td>496.123024</td>\n      <td>2.703626</td>\n      <td>1.328095</td>\n      <td>79442.502883</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>20.000000</td>\n      <td>21.000000</td>\n      <td>1300.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1872.000000</td>\n      <td>1950.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2006.000000</td>\n      <td>34900.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>365.750000</td>\n      <td>20.000000</td>\n      <td>59.000000</td>\n      <td>7553.500000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>1954.000000</td>\n      <td>1967.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>2007.000000</td>\n      <td>129975.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>730.500000</td>\n      <td>50.000000</td>\n      <td>69.000000</td>\n      <td>9478.500000</td>\n      <td>6.000000</td>\n      <td>5.000000</td>\n      <td>1973.000000</td>\n      <td>1994.000000</td>\n      <td>0.000000</td>\n      <td>383.500000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>25.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>2008.000000</td>\n      <td>163000.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1095.250000</td>\n      <td>70.000000</td>\n      <td>80.000000</td>\n      <td>11601.500000</td>\n      <td>7.000000</td>\n      <td>6.000000</td>\n      <td>2000.000000</td>\n      <td>2004.000000</td>\n      <td>166.000000</td>\n      <td>712.250000</td>\n      <td>...</td>\n      <td>168.000000</td>\n      <td>68.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>8.000000</td>\n      <td>2009.000000</td>\n      <td>214000.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1460.000000</td>\n      <td>190.000000</td>\n      <td>313.000000</td>\n      <td>215245.000000</td>\n      <td>10.000000</td>\n      <td>9.000000</td>\n      <td>2010.000000</td>\n      <td>2010.000000</td>\n      <td>1600.000000</td>\n      <td>5644.000000</td>\n      <td>...</td>\n      <td>857.000000</td>\n      <td>547.000000</td>\n      <td>552.000000</td>\n      <td>508.000000</td>\n      <td>480.000000</td>\n      <td>738.000000</td>\n      <td>15500.000000</td>\n      <td>12.000000</td>\n      <td>2010.000000</td>\n      <td>755000.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 38 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Summary statistics for numerical features\nnumerical_features = train_df.select_dtypes(include=[np.number])\nsummary_stats = numerical_features.describe().T\nhtml_numerical = create_scrollable_table(summary_stats, 'numerical_features', 'Summary statistics for numerical features')\n\ndisplay(HTML(html_numerical))","metadata":{"execution":{"iopub.status.busy":"2024-07-12T00:08:18.195301Z","iopub.execute_input":"2024-07-12T00:08:18.197427Z","iopub.status.idle":"2024-07-12T00:08:18.317003Z","shell.execute_reply.started":"2024-07-12T00:08:18.197291Z","shell.execute_reply":"2024-07-12T00:08:18.315599Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<h3>Summary statistics for numerical features</h3><div id=\"numerical_features\" style=\"height:200px; overflow:auto;\"><table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Id</th>\n      <td>1460.0</td>\n      <td>730.500000</td>\n      <td>421.610009</td>\n      <td>1.0</td>\n      <td>365.75</td>\n      <td>730.5</td>\n      <td>1095.25</td>\n      <td>1460.0</td>\n    </tr>\n    <tr>\n      <th>MSSubClass</th>\n      <td>1460.0</td>\n      <td>56.897260</td>\n      <td>42.300571</td>\n      <td>20.0</td>\n      <td>20.00</td>\n      <td>50.0</td>\n      <td>70.00</td>\n      <td>190.0</td>\n    </tr>\n    <tr>\n      <th>LotFrontage</th>\n      <td>1201.0</td>\n      <td>70.049958</td>\n      <td>24.284752</td>\n      <td>21.0</td>\n      <td>59.00</td>\n      <td>69.0</td>\n      <td>80.00</td>\n      <td>313.0</td>\n    </tr>\n    <tr>\n      <th>LotArea</th>\n      <td>1460.0</td>\n      <td>10516.828082</td>\n      <td>9981.264932</td>\n      <td>1300.0</td>\n      <td>7553.50</td>\n      <td>9478.5</td>\n      <td>11601.50</td>\n      <td>215245.0</td>\n    </tr>\n    <tr>\n      <th>OverallQual</th>\n      <td>1460.0</td>\n      <td>6.099315</td>\n      <td>1.382997</td>\n      <td>1.0</td>\n      <td>5.00</td>\n      <td>6.0</td>\n      <td>7.00</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>OverallCond</th>\n      <td>1460.0</td>\n      <td>5.575342</td>\n      <td>1.112799</td>\n      <td>1.0</td>\n      <td>5.00</td>\n      <td>5.0</td>\n      <td>6.00</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>YearBuilt</th>\n      <td>1460.0</td>\n      <td>1971.267808</td>\n      <td>30.202904</td>\n      <td>1872.0</td>\n      <td>1954.00</td>\n      <td>1973.0</td>\n      <td>2000.00</td>\n      <td>2010.0</td>\n    </tr>\n    <tr>\n      <th>YearRemodAdd</th>\n      <td>1460.0</td>\n      <td>1984.865753</td>\n      <td>20.645407</td>\n      <td>1950.0</td>\n      <td>1967.00</td>\n      <td>1994.0</td>\n      <td>2004.00</td>\n      <td>2010.0</td>\n    </tr>\n    <tr>\n      <th>MasVnrArea</th>\n      <td>1452.0</td>\n      <td>103.685262</td>\n      <td>181.066207</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>166.00</td>\n      <td>1600.0</td>\n    </tr>\n    <tr>\n      <th>BsmtFinSF1</th>\n      <td>1460.0</td>\n      <td>443.639726</td>\n      <td>456.098091</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>383.5</td>\n      <td>712.25</td>\n      <td>5644.0</td>\n    </tr>\n    <tr>\n      <th>BsmtFinSF2</th>\n      <td>1460.0</td>\n      <td>46.549315</td>\n      <td>161.319273</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>1474.0</td>\n    </tr>\n    <tr>\n      <th>BsmtUnfSF</th>\n      <td>1460.0</td>\n      <td>567.240411</td>\n      <td>441.866955</td>\n      <td>0.0</td>\n      <td>223.00</td>\n      <td>477.5</td>\n      <td>808.00</td>\n      <td>2336.0</td>\n    </tr>\n    <tr>\n      <th>TotalBsmtSF</th>\n      <td>1460.0</td>\n      <td>1057.429452</td>\n      <td>438.705324</td>\n      <td>0.0</td>\n      <td>795.75</td>\n      <td>991.5</td>\n      <td>1298.25</td>\n      <td>6110.0</td>\n    </tr>\n    <tr>\n      <th>1stFlrSF</th>\n      <td>1460.0</td>\n      <td>1162.626712</td>\n      <td>386.587738</td>\n      <td>334.0</td>\n      <td>882.00</td>\n      <td>1087.0</td>\n      <td>1391.25</td>\n      <td>4692.0</td>\n    </tr>\n    <tr>\n      <th>2ndFlrSF</th>\n      <td>1460.0</td>\n      <td>346.992466</td>\n      <td>436.528436</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>728.00</td>\n      <td>2065.0</td>\n    </tr>\n    <tr>\n      <th>LowQualFinSF</th>\n      <td>1460.0</td>\n      <td>5.844521</td>\n      <td>48.623081</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>572.0</td>\n    </tr>\n    <tr>\n      <th>GrLivArea</th>\n      <td>1460.0</td>\n      <td>1515.463699</td>\n      <td>525.480383</td>\n      <td>334.0</td>\n      <td>1129.50</td>\n      <td>1464.0</td>\n      <td>1776.75</td>\n      <td>5642.0</td>\n    </tr>\n    <tr>\n      <th>BsmtFullBath</th>\n      <td>1460.0</td>\n      <td>0.425342</td>\n      <td>0.518911</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>BsmtHalfBath</th>\n      <td>1460.0</td>\n      <td>0.057534</td>\n      <td>0.238753</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>FullBath</th>\n      <td>1460.0</td>\n      <td>1.565068</td>\n      <td>0.550916</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>2.0</td>\n      <td>2.00</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>HalfBath</th>\n      <td>1460.0</td>\n      <td>0.382877</td>\n      <td>0.502885</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>BedroomAbvGr</th>\n      <td>1460.0</td>\n      <td>2.866438</td>\n      <td>0.815778</td>\n      <td>0.0</td>\n      <td>2.00</td>\n      <td>3.0</td>\n      <td>3.00</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>KitchenAbvGr</th>\n      <td>1460.0</td>\n      <td>1.046575</td>\n      <td>0.220338</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>1.0</td>\n      <td>1.00</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>TotRmsAbvGrd</th>\n      <td>1460.0</td>\n      <td>6.517808</td>\n      <td>1.625393</td>\n      <td>2.0</td>\n      <td>5.00</td>\n      <td>6.0</td>\n      <td>7.00</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>Fireplaces</th>\n      <td>1460.0</td>\n      <td>0.613014</td>\n      <td>0.644666</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>1.0</td>\n      <td>1.00</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>GarageYrBlt</th>\n      <td>1379.0</td>\n      <td>1978.506164</td>\n      <td>24.689725</td>\n      <td>1900.0</td>\n      <td>1961.00</td>\n      <td>1980.0</td>\n      <td>2002.00</td>\n      <td>2010.0</td>\n    </tr>\n    <tr>\n      <th>GarageCars</th>\n      <td>1460.0</td>\n      <td>1.767123</td>\n      <td>0.747315</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>2.0</td>\n      <td>2.00</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>GarageArea</th>\n      <td>1460.0</td>\n      <td>472.980137</td>\n      <td>213.804841</td>\n      <td>0.0</td>\n      <td>334.50</td>\n      <td>480.0</td>\n      <td>576.00</td>\n      <td>1418.0</td>\n    </tr>\n    <tr>\n      <th>WoodDeckSF</th>\n      <td>1460.0</td>\n      <td>94.244521</td>\n      <td>125.338794</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>168.00</td>\n      <td>857.0</td>\n    </tr>\n    <tr>\n      <th>OpenPorchSF</th>\n      <td>1460.0</td>\n      <td>46.660274</td>\n      <td>66.256028</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>25.0</td>\n      <td>68.00</td>\n      <td>547.0</td>\n    </tr>\n    <tr>\n      <th>EnclosedPorch</th>\n      <td>1460.0</td>\n      <td>21.954110</td>\n      <td>61.119149</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>552.0</td>\n    </tr>\n    <tr>\n      <th>3SsnPorch</th>\n      <td>1460.0</td>\n      <td>3.409589</td>\n      <td>29.317331</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>508.0</td>\n    </tr>\n    <tr>\n      <th>ScreenPorch</th>\n      <td>1460.0</td>\n      <td>15.060959</td>\n      <td>55.757415</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>480.0</td>\n    </tr>\n    <tr>\n      <th>PoolArea</th>\n      <td>1460.0</td>\n      <td>2.758904</td>\n      <td>40.177307</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>738.0</td>\n    </tr>\n    <tr>\n      <th>MiscVal</th>\n      <td>1460.0</td>\n      <td>43.489041</td>\n      <td>496.123024</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>15500.0</td>\n    </tr>\n    <tr>\n      <th>MoSold</th>\n      <td>1460.0</td>\n      <td>6.321918</td>\n      <td>2.703626</td>\n      <td>1.0</td>\n      <td>5.00</td>\n      <td>6.0</td>\n      <td>8.00</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>YrSold</th>\n      <td>1460.0</td>\n      <td>2007.815753</td>\n      <td>1.328095</td>\n      <td>2006.0</td>\n      <td>2007.00</td>\n      <td>2008.0</td>\n      <td>2009.00</td>\n      <td>2010.0</td>\n    </tr>\n    <tr>\n      <th>SalePrice</th>\n      <td>1460.0</td>\n      <td>180921.195890</td>\n      <td>79442.502883</td>\n      <td>34900.0</td>\n      <td>129975.00</td>\n      <td>163000.0</td>\n      <td>214000.00</td>\n      <td>755000.0</td>\n    </tr>\n  </tbody>\n</table></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### 1.2 Categorical Data","metadata":{}},{"cell_type":"code","source":"# Summary statistics for categorical features\ncategorical_features = train_df.select_dtypes(include=[object])\ncat_summary_stats = categorical_features.describe().T\nhtml_categorical = create_scrollable_table(cat_summary_stats, 'categorical_features', 'Summary statistics for categorical features')\n\ndisplay(HTML(html_categorical ))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.3 Null Values in Dataset","metadata":{}},{"cell_type":"code","source":"# Null values in the dataset\nnull_values = train_df.isnull().sum()\nhtml_null_values = create_scrollable_table(null_values.to_frame(), 'null_values', 'Null values in the dataset')\n\n# Percentage of missing values for each feature\nmissing_percentage = (train_df.isnull().sum() / len(train_df)) * 100\nhtml_missing_percentage = create_scrollable_table(missing_percentage.to_frame(), 'missing_percentage', 'Percentage of missing values for each feature')\n\ndisplay(HTML(html_null_values + html_missing_percentage))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.4 Missing Values in Dataset","metadata":{}},{"cell_type":"code","source":"# Exploring rows with missing values\nrows_with_missing_values = train_df[train_df.isnull().any(axis=1)]\nhtml_rows_with_missing_values = create_scrollable_table(rows_with_missing_values.head(), 'rows_with_missing_values', 'Rows with missing values')\n\ndisplay(HTML(html_rows_with_missing_values))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.5 Explore the columns","metadata":{}},{"cell_type":"code","source":"train_df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.6 Explore the dependent variable\n- Should it be normalized?\n- Normalize Dependent Variable","metadata":{}},{"cell_type":"code","source":"# Fit a normal distribution to the SalePrice data\nmu, sigma = stats.norm.fit(train_df['SalePrice'])\n\n# Create a histogram of the SalePrice column\nhist_data = go.Histogram(\n    x=train_df['SalePrice'],\n    nbinsx=50,\n    name=\"Histogram\",\n    opacity=0.75,\n    histnorm='probability density',\n    marker=dict(color='lightsalmon')  # Change color to lightsalmon\n)\n\n# Calculate the normal distribution based on the fitted parameters\nx_norm = np.linspace(train_df['SalePrice'].min(), train_df['SalePrice'].max(), 100)\ny_norm = stats.norm.pdf(x_norm, mu, sigma)\n\n# Create the normal distribution overlay\nnorm_data = go.Scatter(\n    x=x_norm,\n    y=y_norm,\n    mode=\"lines\",\n    name=f\"Normal dist. (Î¼={mu:.2f}, Ïƒ={sigma:.2f})\",\n    line=dict(color=\"blue\")  # Change line color to blue\n)\n\n# Combine the histogram and the overlay\nfig = go.Figure(data=[hist_data, norm_data])\n\n# Set the layout for the plot\nfig.update_layout(\n    title=\"SalePrice Distribution\",\n    xaxis_title=\"SalePrice\",\n    yaxis_title=\"Density\",\n    legend_title_text=\"Fitted Normal Distribution\",\n    # Adjusting grid and axis line visibility\n    xaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    yaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    plot_bgcolor='rgba(255, 255, 255, 1)',  # White background\n    paper_bgcolor='rgba(255, 255, 255, 1)',\n    font=dict(color='black')  # Adjust font color to black for better readability\n)\n\n# Create a Q-Q plot\nqq_data = stats.probplot(train_df['SalePrice'], dist=\"norm\")\nqq_fig = px.scatter(\n    x=qq_data[0][0],\n    y=qq_data[0][1],\n    labels={'x': 'Theoretical Quantiles', 'y': 'Ordered Values'},\n    color_discrete_sequence=[\"lightsalmon\"]  # Change color to lightsalmon\n)\n\n# Update layout for Q-Q plot\nqq_fig.update_layout(\n    title=\"Q-Q plot\",\n    # Adjusting grid and axis line visibility\n    xaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    yaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    plot_bgcolor='rgba(255, 255, 255, 1)',  # White background\n    paper_bgcolor='rgba(255, 255, 255, 1)',\n    font=dict(color='black')  # Adjust font color to black\n)\n\n# Calculate the line of best fit\nslope, intercept, r_value, p_value, std_err = stats.linregress(qq_data[0][0], qq_data[0][1])\nline_x = np.array(qq_data[0][0])\nline_y = intercept + slope * line_x\n\n# Add the line of best fit to the Q-Q plot\nline_data = go.Scatter(\n    x=line_x,\n    y=line_y,\n    mode=\"lines\",\n    name=\"Normal Line\",\n    line=dict(color=\"blue\")  # Change line color to blue\n)\n\n# Update the Q-Q plot with the normal line\nqq_fig.add_trace(line_data)\n\n# Show the plots\n#fig.show()\n#qq_fig.show()\n\n# Save the Plotly figures as static PNG images\nfig.write_image(\"saleprice_distribution.png\", engine=\"kaleido\")\nqq_fig.write_image(\"qqplot.png\", engine=\"kaleido\")\n\n\n# (Optional: Display the images in the notebook if you're working in Kaggle)\nfrom IPython.display import Image\ndisplay(Image(\"saleprice_distribution.png\"))\ndisplay(Image(\"qqplot.png\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Interpretation of Plots\n\n#### SalePrice Distribution:\n\n- The histogram shows the SalePrice is right-skewed (tail on the right). This is common with house prices as there are typically fewer extremely expensive houses.\n- The normal distribution (blue curve) doesn't fit the data well, confirming the non-normality.\n\n#### Q-Q Plot:\n\n- The points deviate significantly from the straight blue line, especially in the upper tail. This further emphasizes that SalePrice does not follow a normal distribution.\n- The upward curve indicates the right skew we saw in the histogram.","metadata":{}},{"cell_type":"markdown","source":"### 1.7 Basic Data Exploration\n**Next, let's try to address the following questions through the data in hand:**\n\n- How do various dwelling types distribute, and how are they related to sale prices?\n- Is there an effect of zoning on sale prices?\n- What impact do different types of street and alley access have on sale prices?\n- What is the average sale price based on property shape?\n- Is there a correlation between the age of a property and its sale price?\n- Is there a correlation between the living area size and sale price?\n- Do sale prices fluctuate from year to year?","metadata":{}},{"cell_type":"markdown","source":"#### 1.7.1 Dwelling Types Distribute Relation to Sale Price ","metadata":{}},{"cell_type":"code","source":"# Bar plot for MSSubClass distribution\nfig_bar = px.histogram(train_df, x='MSSubClass', title='Distribution of Dwelling Types (MSSubClass)')\nfig_bar.update_layout(\n    xaxis_title='Dwelling Type (MSSubClass)',\n    yaxis_title='Count',\n    xaxis_tickangle=-45,\n    font=dict(color='black'),  \n    xaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    yaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    plot_bgcolor='rgba(255, 255, 255, 1)',\n    paper_bgcolor='rgba(255, 255, 255, 1)'\n)\n#fig_bar.show()\n\n# Save bar plot as a static image\nfig_bar.write_image(\"mssubclass_distribution_bar.png\", engine=\"kaleido\")\n\n# Box plot for MSSubClass vs SalePrice\nfig_box = px.box(train_df, x='MSSubClass', y='SalePrice', title='SalePrice vs Dwelling Type (MSSubClass)')\nfig_box.update_layout(\n    xaxis_title='Dwelling Type (MSSubClass)',\n    yaxis_title='SalePrice',\n    xaxis_tickangle=-45,\n    font=dict(color='black'),\n    xaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    yaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    plot_bgcolor='rgba(255, 255, 255, 1)',\n    paper_bgcolor='rgba(255, 255, 255, 1)'\n)\n#fig_box.show()\n\n# Save box plot as a static image\nfig_box.write_image(\"saleprice_vs_mssubclass_box.png\", engine=\"kaleido\")\n\n\n# (Optional: Display the images in the notebook if you're working in Kaggle)\nfrom IPython.display import Image\ndisplay(Image(\"mssubclass_distribution_bar.png\"))\ndisplay(Image(\"saleprice_vs_mssubclass_box.png\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">**1. Distribution of Dwelling Types (MSSubClass)**\n>- The bar plot illustrates the frequency of each dwelling type in the dataset, providing insight into how common each type is among the properties.\n>\n>**2. SalePrice vs Dwelling Type (MSSubClass)**\n>- The box plot depicts the distribution of sale prices for each dwelling type, offering an understanding of how sale prices vary across different types of dwellings.","metadata":{}},{"cell_type":"markdown","source":"#### 1.7.2 Effect of Zoning on Sale Prices","metadata":{}},{"cell_type":"code","source":"# Bar plot for MSZoning distribution\nfig_bar_zoning = px.histogram(train_df, x='MSZoning', title='Distribution of Zoning Classifications (MSZoning)', color_discrete_sequence=['rgb(156, 39, 176)'])\nfig_bar_zoning.update_layout(\n    xaxis_title='Zoning Classification (MSZoning)',\n    yaxis_title='Count',\n    xaxis_tickangle=-45,\n    font=dict(color='black'),  # Set font color to black\n    xaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    yaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    plot_bgcolor='rgba(255, 255, 255, 1)',  # White background\n    paper_bgcolor='rgba(255, 255, 255, 1)'\n)\n#fig_bar_zoning.show()\n\n# Save bar plot as a static image\nfig_bar_zoning.write_image(\"mszoning_distribution_bar.png\", engine=\"kaleido\")\n\n# Box plot for MSZoning vs SalePrice\nfig_box_zoning = px.box(train_df, x='MSZoning', y='SalePrice', title='SalePrice vs Zoning Classification (MSZoning)', color_discrete_sequence=['rgb(156, 39, 176)'])\nfig_box_zoning.update_layout(\n    xaxis_title='Zoning Classification (MSZoning)',\n    yaxis_title='SalePrice',\n    xaxis_tickangle=-45,\n    font=dict(color='black'),  # Set font color to black\n    xaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    yaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    plot_bgcolor='rgba(255, 255, 255, 1)',  # White background\n    paper_bgcolor='rgba(255, 255, 255, 1)'\n)\n#fig_box_zoning.show()\n\n# Save box plot as a static image\nfig_box_zoning.write_image(\"saleprice_vs_mszoning_box.png\", engine=\"kaleido\")\n\n\n# (Optional: Display the images in the notebook if you're working in Kaggle)\nfrom IPython.display import Image\ndisplay(Image(\"mszoning_distribution_bar.png\"))\ndisplay(Image(\"saleprice_vs_mszoning_box.png\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">**1. Distribution of Zoning Classifications (MSZoning)**\n>- The bar plot illustrates the frequency of each zoning classification in the dataset, offering insight into how common each zoning type is among the properties.\n>\n>**2. SalePrice vs. Zoning Classification (MSZoning)**\n>- The box plot depicts the distribution of sale prices for each zoning classification, helping to understand how sale prices vary across different zoning categories.","metadata":{}},{"cell_type":"markdown","source":"#### 1.7.3 Impact of different types of street and alley access on Sale Prices","metadata":{}},{"cell_type":"code","source":"# Bar plot for Street distribution\nfig_bar_street = px.histogram(train_df, x='Street', title='Distribution of Street Types', color_discrete_sequence=['rgb(255, 193, 7)'])\nfig_bar_street.update_layout(\n    xaxis_title='Street Type',\n    yaxis_title='Count',\n    xaxis_tickangle=-45,\n    font=dict(color='black'),  # Set font color to black\n    xaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    yaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    plot_bgcolor='rgba(255, 255, 255, 1)',  # White background\n    paper_bgcolor='rgba(255, 255, 255, 1)'\n)\n#fig_bar_street.show()\n\n# Save bar plot as a static image\nfig_bar_street.write_image(\"street_distribution_bar.png\", engine=\"kaleido\")\n\n# Box plot for Street vs SalePrice\nfig_box_street = px.box(train_df, x='Street', y='SalePrice', title='SalePrice vs Street Type', color_discrete_sequence=['rgb(255, 193, 7)'])\nfig_box_street.update_layout(\n    xaxis_title='Street Type',\n    yaxis_title='SalePrice',\n    xaxis_tickangle=-45,\n    font=dict(color='black'),  # Set font color to black\n    xaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    yaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    plot_bgcolor='rgba(255, 255, 255, 1)',  # White background\n    paper_bgcolor='rgba(255, 255, 255, 1)'\n)\n#fig_box_street.show()\n\n# Save box plot as a static image\nfig_box_street.write_image(\"saleprice_vs_street_box.png\", engine=\"kaleido\")\n\n# Bar plot for Alley distribution\nfig_bar_alley = px.histogram(train_df, x='Alley', title='Distribution of Alley Types', color_discrete_sequence=['rgb(139, 195, 74)'])\nfig_bar_alley.update_layout(\n    xaxis_title='Alley Type',\n    yaxis_title='Count',\n    xaxis_tickangle=-45,\n    font=dict(color='black'),  # Set font color to black\n    xaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    yaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    plot_bgcolor='rgba(255, 255, 255, 1)',  # White background\n    paper_bgcolor='rgba(255, 255, 255, 1)'\n)\n#fig_bar_alley.show()\n\n# Save bar plot as a static image\nfig_bar_alley.write_image(\"alley_distribution_bar.png\", engine=\"kaleido\")\n\n# Box plot for Alley vs SalePrice\nfig_box_alley = px.box(train_df, x='Alley', y='SalePrice', title='SalePrice vs Alley Type', color_discrete_sequence=['rgb(139, 195, 74)'])\nfig_box_alley.update_layout(\n    xaxis_title='Alley Type',\n    yaxis_title='SalePrice',\n    xaxis_tickangle=-45,\n    font=dict(color='black'),  # Set font color to black\n    xaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    yaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    plot_bgcolor='rgba(255, 255, 255, 1)',  # White background\n    paper_bgcolor='rgba(255, 255, 255, 1)'\n)\n#fig_box_alley.show()\n\n# Save box plot as a static image\nfig_box_alley.write_image(\"saleprice_vs_alley_box.png\", engine=\"kaleido\")\n\n\n# (Optional: Display the images in the notebook if you're working in Kaggle)\nfrom IPython.display import Image\ndisplay(Image(\"street_distribution_bar.png\"))\ndisplay(Image(\"saleprice_vs_street_box.png\"))\ndisplay(Image(\"alley_distribution_bar.png\"))\ndisplay(Image(\"saleprice_vs_alley_box.png\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">**1. Distribution of Street Types**\n>- The bar plot highlights the frequency of gravel and paved streets in the dataset, revealing that most properties have paved streets.\n>\n>**2. SalePrice vs. Street Type**\n>- The box plot illustrates the distribution of sale prices for properties with gravel and paved streets, showing that properties with paved streets generally command higher sale prices.\n>\n>**3. Distribution of Alley Types**\n>- The bar plot shows the frequency of gravel, paved, and no alley types in the dataset, with most properties lacking alley access.\n>\n>**4. SalePrice vs. Alley Type**\n>- The box plot depicts the distribution of sale prices based on alley types, indicating that properties without alley access typically have higher sale prices than those with gravel or paved alley access.","metadata":{}},{"cell_type":"markdown","source":"#### 1.7.3 Average Sale Price based on Property Shape","metadata":{}},{"cell_type":"code","source":"# Bar plot for LotShape distribution\nfig_bar_lotshape = px.histogram(train_df, x='LotShape', title='Distribution of Lot Shapes', color_discrete_sequence=['rgb(103, 58, 183)'])\nfig_bar_lotshape.update_layout(\n    xaxis_title='Lot Shape',\n    yaxis_title='Count',\n    xaxis_tickangle=-45,\n    font=dict(color='black'),  # Set font color to black\n    xaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    yaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    plot_bgcolor='rgba(255, 255, 255, 1)',  # White background\n    paper_bgcolor='rgba(255, 255, 255, 1)'\n)\n#fig_bar_lotshape.show()\n\n# Save bar plot as a static image\nfig_bar_lotshape.write_image(\"lotshape_distribution_bar.png\", engine=\"kaleido\")\n\n# Box plot for LotShape vs SalePrice\nfig_box_lotshape = px.box(train_df, x='LotShape', y='SalePrice', title='SalePrice vs Lot Shape', color_discrete_sequence=['rgb(103, 58, 183)'])\nfig_box_lotshape.update_layout(\n    xaxis_title='Lot Shape',\n    yaxis_title='SalePrice',\n    xaxis_tickangle=-45,\n    font=dict(color='black'),  # Set font color to black\n    xaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    yaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    plot_bgcolor='rgba(255, 255, 255, 1)',  # White background\n    paper_bgcolor='rgba(255, 255, 255, 1)'\n)\n#fig_box_lotshape.show()\n\n# Save box plot as a static image\nfig_box_lotshape.write_image(\"saleprice_vs_lotshape_box.png\", engine=\"kaleido\")\n\n\n# (Optional: Display the images in the notebook if you're working in Kaggle)\nfrom IPython.display import Image\ndisplay(Image(\"lotshape_distribution_bar.png\"))\ndisplay(Image(\"saleprice_vs_lotshape_box.png\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">**1. Distribution of Lot Shapes**\n>- The bar plot illustrates the frequency of various lot shapes in the dataset, showing that regular (Reg) lot shapes are the most common, followed by slightly irregular (IR1) shapes.\n>\n>**2. SalePrice vs. Lot Shape**\n>- The box plot depicts the distribution of sale prices for different lot shapes, indicating that regular (Reg) lot shapes generally have higher sale prices compared to irregular shapes.","metadata":{}},{"cell_type":"markdown","source":"#### 1.7.4 Correlation between the Age of a Property and Sale Proces","metadata":{}},{"cell_type":"code","source":"# Create a new column for the age of the property\ntrain_df['HouseAge'] = train_df['YrSold'] - train_df['YearBuilt']\n\n# Scatter plot for YearBuilt vs SalePrice\nfig_scatter_yearbuilt = px.scatter(train_df, x='YearBuilt', y='SalePrice', title='SalePrice vs YearBuilt')\nfig_scatter_yearbuilt.update_traces(marker=dict(color='rgb(0, 123, 255)'))\nfig_scatter_yearbuilt.update_layout(\n    xaxis_title='Year Built',\n    yaxis_title='SalePrice',\n    font=dict(color='black'),  # Set font color to black\n    xaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    yaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    plot_bgcolor='rgba(255, 255, 255, 1)',  # White background\n    paper_bgcolor='rgba(255, 255, 255, 1)'\n)\n#fig_scatter_yearbuilt.show()\n\n# Save YearBuilt scatter plot as a static image\nfig_scatter_yearbuilt.write_image(\"saleprice_vs_yearbuilt_scatter.png\", engine=\"kaleido\")\n\n# Scatter plot for HouseAge vs SalePrice\nfig_scatter_houseage = px.scatter(train_df, x='HouseAge', y='SalePrice', title='SalePrice vs House Age')\nfig_scatter_houseage.update_traces(marker=dict(color='rgb(255, 193, 7)'))\nfig_scatter_houseage.update_layout(\n    xaxis_title='House Age',\n    yaxis_title='SalePrice',\n    font=dict(color='black'),  # Set font color to black\n    xaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    yaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    plot_bgcolor='rgba(255, 255, 255, 1)',  # White background\n    paper_bgcolor='rgba(255, 255, 255, 1)'\n)\n#fig_scatter_houseage.show()\n\n# Save HouseAge scatter plot as a static image\nfig_scatter_houseage.write_image(\"saleprice_vs_houseage_scatter.png\", engine=\"kaleido\")\n\n# Previous lines to show the plots are commented out (Optional: Display the images in the notebook if you're working in Kaggle)\n# fig_scatter_yearbuilt.show()\n# fig_scatter_houseage.show()\n\nfrom IPython.display import Image\ndisplay(Image(\"saleprice_vs_yearbuilt_scatter.png\"))\ndisplay(Image(\"saleprice_vs_houseage_scatter.png\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">**1. SalePrice vs. Year Built**\n>- The scatter plot illustrates the relationship between the year a property was built and its sale price. Typically, newer properties command higher sale prices compared to older ones.\n>\n>**2. SalePrice vs. House Age**\n>- The scatter plot depicts the relationship between a property's age and its sale price. There is a negative correlation, indicating that as a property ages, its sale price tends to decrease.","metadata":{}},{"cell_type":"markdown","source":"#### 1.7.6 Correlation between the Living Area Size and Sale Prices","metadata":{}},{"cell_type":"code","source":"# Scatter plot for GrLivArea vs SalePrice\nfig_scatter_grlivarea = px.scatter(train_df, x='GrLivArea', y='SalePrice', title='SalePrice vs GrLivArea')\nfig_scatter_grlivarea.update_traces(marker=dict(color='rgb(40, 167, 69)'))\nfig_scatter_grlivarea.update_layout(\n    xaxis_title='Above Ground Living Area (GrLivArea)',\n    yaxis_title='SalePrice',\n    font=dict(color='black'),  # Set font color to black\n    xaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    yaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    plot_bgcolor='rgba(255, 255, 255, 1)',  # White background\n    paper_bgcolor='rgba(255, 255, 255, 1)'\n)\n#fig_scatter_grlivarea.show()\n\n# Save the scatter plot as a static image\nfig_scatter_grlivarea.write_image(\"saleprice_vs_grlivarea_scatter.png\", engine=\"kaleido\")\n\n\n# (Optional: Display the image in the notebook if you're working in Kaggle)\nfrom IPython.display import Image\ndisplay(Image(\"saleprice_vs_grlivarea_scatter.png\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">**SalePrice vs. GrLivArea**\n>- The scatter plot highlights a clear positive correlation between above-ground living area size (GrLivArea) and sale price (SalePrice). Generally, properties with larger living areas tend to fetch higher sale prices.","metadata":{}},{"cell_type":"markdown","source":"#### 1.7.7 Sale Prices Fluctuation Y-Y","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\n\n# Calculate the median SalePrice for each year\nmedian_saleprice_per_year = train_df.groupby('YrSold')['SalePrice'].median().reset_index()\n\n# Line plot for Median SalePrice over different years\nfig_line_saleprice = px.line(median_saleprice_per_year, x='YrSold', y='SalePrice', title='Median SalePrice over Years', markers=True, line_shape='linear')\nfig_line_saleprice.update_traces(line=dict(color='rgb(255, 99, 132)'))\nfig_line_saleprice.update_layout(\n    xaxis_title='Year Sold',\n    yaxis_title='Median SalePrice',\n    font=dict(color='black'),  # Set font color to black\n    xaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    yaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n    plot_bgcolor='rgba(255, 255, 255, 1)',  # White background\n    paper_bgcolor='rgba(255, 255, 255, 1)'\n)\n#fig_line_saleprice.show()\n\n# Save the scatter plot as a static image\nfig_line_saleprice.write_image(\"saleprice_fluctuation.png\", engine=\"kaleido\")\n\n\n# (Optional: Display the image in the notebook if you're working in Kaggle)\nfrom IPython.display import Image\ndisplay(Image(\"saleprice_fluctuation.png\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">**Median SalePrice Over the Years**\n>- The line plot illustrates the trend of median sale prices from 2006 to 2010. There is a noticeable decline in median sale prices during this period, particularly after 2007, likely due to the economic downturn at that time.","metadata":{}},{"cell_type":"markdown","source":"## 2. Data Processing\n\n### 2.1 Handling Missing Values","metadata":{}},{"cell_type":"code","source":"# Step 2a: Handle Missing Values\n# Identify columns with missing values\nmissing_values_before = train_df.isnull().sum()\nmissing_values_before = missing_values_before[missing_values_before > 0]\n\n# Display missing values before imputation\nscrollable_table_before_html = create_scrollable_table(missing_values_before.to_frame(name='Missing Values Before Imputation'), \"missing-values-before-table\", \"Missing Values Before Imputation\")\ndisplay(HTML(scrollable_table_before_html))\n\n# Impute missing numerical values with the median\nnum_cols = train_df.select_dtypes(include=['float64', 'int64']).columns\ntrain_df[num_cols] = train_df[num_cols].apply(lambda x: x.fillna(x.median()), axis=0)\n\n# Impute missing categorical values with 'None'\ncat_cols = train_df.select_dtypes(include=['object']).columns\ntrain_df[cat_cols] = train_df[cat_cols].apply(lambda x: x.fillna('None'), axis=0)\n\n# Display the dataframe of missing values after imputation\nmissing_values_after = train_df.isnull().sum()\nmissing_values_after = missing_values_after[missing_values_after > 0]\n\n# Create scrollable table for after imputation\n#scrollable_table_after_html = create_scrollable_table(missing_values_after.to_frame(name='Missing Values After Imputation'), \"missing-values-after-table\", \"Missing Values After Imputation\")\n#display(HTML(scrollable_table_after_html))\n\ndisplay(\"All Missing Values Handled!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2.2 Encode Categorical Variables:","metadata":{}},{"cell_type":"code","source":"# Step 2b: Encode Categorical Variables\ntrain_df = pd.get_dummies(train_df, drop_first=True)\n\n# Normalize/Standardize Numerical Features\nscaler = StandardScaler()\nnum_cols = train_df.select_dtypes(include=['float64', 'int64']).columns\ntrain_df[num_cols] = scaler.fit_transform(train_df[num_cols])\n\n# Display the preprocessed data sample\nscrollable_table_sample_html = create_scrollable_table(train_df.head(), \"preprocessed-data-sample-table\", \"Preprocessed Data Sample\")\ndisplay(HTML(scrollable_table_sample_html))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">The preprocessing steps have been successfully completed, including the handling of missing values, encoding of categorical variables, and standardization of numerical features. The data is now preprocessed and ready for further analysis.","metadata":{}},{"cell_type":"markdown","source":"## 3. Exploratory Data Analysis (EDA)\n### 3.1 Visualize Distributions and Relationships\n- We will create histograms, box plots, and scatter plots for numerical variables.\n- We will use bar plots for categorical variables.","metadata":{}},{"cell_type":"code","source":"# Step 3a: Visualize Distributions and Relationships\n# Create histograms, box plots, and scatter plots for numerical variables\n# Plotting histograms for selected numerical features\nnum_features = ['LotArea', 'GrLivArea', 'TotalBsmtSF', 'SalePrice']\nplt.figure(figsize=(16, 10))\nfor i, feature in enumerate(num_features):\n    plt.subplot(2, 2, i + 1)\n    sns.histplot(train_df[feature], kde=True)\n    plt.title(f'Distribution of {feature}')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.2 Correlation Analysis\n- Let's Compute and visualize the correlation matrix using a heatmap to uncover relationships between numerical features.","metadata":{}},{"cell_type":"code","source":"# Step 3b: Correlation Analysis\n# Compute and visualize the correlation matrix using a heatmap\ncorrelation_matrix = train_df.corr()\nplt.figure(figsize=(16, 10))\nsns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', linewidths=0.5)\nplt.title('Correlation Matrix Heatmap')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3.3 Analyze the Target Variable (SalePrice)\n- Let's Eexamine the distribution of SalePrice and apply a log transformation to address skewness.","metadata":{}},{"cell_type":"code","source":"# Step 3c: Analyze the Target Variable (SalePrice)\n# Examine the distribution of SalePrice and apply a log transformation to address skewness\nplt.figure(figsize=(8, 6))\nsns.histplot(np.log1p(train_df['SalePrice']), kde=True)\nplt.title('Log-Transformed Distribution of SalePrice')\nplt.xlabel('Log(SalePrice)')\nplt.ylabel('Frequency')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">**1.Distributions of Numerical Variables**\n>- Histograms for LotArea, GrLivArea, TotalBsmtSF, and SalePrice illustrate the distribution and highlight the presence of outliers in these features.\n>\n>**2. Correlation Analysis**\n>- A heatmap of the correlation matrix uncovers relationships between numerical features, showing strong correlations, such as between GrLivArea and TotalBsmtSF with SalePrice.\n>\n>**3. Analysis of the Target Variable (SalePrice)**\n>- The log-transformed distribution of SalePrice demonstrates that log transformation helps address skewness, making the data more normally distributed.","metadata":{}},{"cell_type":"markdown","source":"## 4. Feature Engineering\n### a. Create New Features\n- TotalHouseArea: Combine the above-ground living area (GrLivArea) and the basement area (TotalBsmtSF).\n- TotalBathrooms: Sum all full and half bathrooms across different levels.\n- HouseAge: Calculate the difference between the year sold (YrSold) and the year built (YearBuilt).\n- RemodelAge: Calculate the difference between the year sold (YrSold) and the year of the last remodel (YearRemodAdd).\n\n### b. Handle Interaction Terms\n- Consider interaction terms between features that may have a combined influence on SalePrice.\n\n### c. Feature Selection\n- Use tree-based feature importance to identify the most relevant features.","metadata":{"execution":{"iopub.status.busy":"2024-07-10T00:50:27.422761Z","iopub.execute_input":"2024-07-10T00:50:27.423213Z","iopub.status.idle":"2024-07-10T00:50:27.433307Z","shell.execute_reply.started":"2024-07-10T00:50:27.423178Z","shell.execute_reply":"2024-07-10T00:50:27.431654Z"}}},{"cell_type":"code","source":"# Step 4a: Create New Features\n\n# TotalHouseArea: Combine above-ground living area (GrLivArea) and basement area (TotalBsmtSF)\ntrain_df['TotalHouseArea'] = train_df['GrLivArea'] + train_df['TotalBsmtSF']\n\n# TotalBathrooms: Sum up all full and half bathrooms across different levels\ntrain_df['TotalBathrooms'] = (train_df['FullBath'] + 0.5 * train_df['HalfBath'] + \n                              train_df['BsmtFullBath'] + 0.5 * train_df['BsmtHalfBath'])\n\n# HouseAge: Calculate the difference between the year sold (YrSold) and the year built (YearBuilt)\ntrain_df['HouseAge'] = train_df['YrSold'] - train_df['YearBuilt']\n\n# RemodelAge: Calculate the difference between the year sold (YrSold) and the year of the last remodel (YearRemodAdd)\ntrain_df['RemodelAge'] = train_df['YrSold'] - train_df['YearRemodAdd']\n\n# Display a sample of the feature-engineered dataframe in a scrollable table\nscrollable_table_html = create_scrollable_table(train_df.head(), \"feature_engineered_table\", \"Feature Engineered Data Sample\")\ndisplay(HTML(scrollable_table_html))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Model Building\n\na. Split the Data into Training and Validation Sets:","metadata":{"execution":{"iopub.status.busy":"2024-07-10T23:54:12.486448Z","iopub.execute_input":"2024-07-10T23:54:12.487238Z","iopub.status.idle":"2024-07-10T23:54:12.491652Z","shell.execute_reply.started":"2024-07-10T23:54:12.487202Z","shell.execute_reply":"2024-07-10T23:54:12.490518Z"}}},{"cell_type":"code","source":"# Define Your Features (X) and Target (y)\nX = train_df.drop('SalePrice', axis=1)\ny = train_df['SalePrice']\n\n# Split the data\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"b. Train multiple models","metadata":{}},{"cell_type":"code","source":"# Import the models\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n\n# Initialize the Models\nlr = LinearRegression()\nrf = RandomForestRegressor(n_estimators=100, random_state=42)\ngbr = GradientBoostingRegressor(n_estimators=100, random_state=42)\n\n# Train Each Model\n# Train Linear Regression\nlr.fit(X_train, y_train)\n\n# Train Random Forest Regressor\nrf.fit(X_train, y_train)\n\n# Train Gradient Boosting Regressor\ngbr.fit(X_train, y_train)\n\n# Predict on the Validation Set\ny_pred_lr = lr.predict(X_val)\ny_pred_rf = rf.predict(X_val)\ny_pred_gbr = gbr.predict(X_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"c. Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport numpy as np\n\n# Calculate RMSE for Linear Regression\nrmse_lr = np.sqrt(mean_squared_error(y_val, y_pred_lr))\n\n# Calculate RMSE for Random Forest\nrmse_rf = np.sqrt(mean_squared_error(y_val, y_pred_rf))\n\n# Calculate RMSE for Gradient Boosting Regressor\nrmse_gbr = np.sqrt(mean_squared_error(y_val, y_pred_gbr))\n\n# Print results in markdown table format\nresults = f\"\"\"\n| Model                        | RMSE       |\n|------------------------------|------------|\n| Linear Regression            | {rmse_lr:.4f} |\n| Random Forest                | {rmse_rf:.4f} |\n| Gradient Boosting Regressor  | {rmse_gbr:.4f} |\n\"\"\"\nprint(results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**RMSE Results for the Models**\n\n- Linear Regression: RMSE = 1.045\n- Random Forest: RMSE = 0.368\n- Gradient Boosting: RMSE = 0.339\n\nFrom these RMSE values, it is evident that the Gradient Boosting Regressor delivers the best performance, closely followed by the Random Forest Regressor. The Linear Regression model, with the highest RMSE, is the least accurate of the three.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\n# Define the models\nmodels = {\n    'Linear Regression': LinearRegression(),\n    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n}\n\n# Evaluate each model using cross-validation and calculate RMSE\ncv_results = {}\nfor name, model in models.items():\n    # Perform cross-validation\n    scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)\n    # Calculate RMSE\n    rmse_scores = np.sqrt(-scores)\n    cv_results[name] = rmse_scores\n    print(f'{name} Cross-Validation RMSE: {rmse_scores.mean():.4f} Â± {rmse_scores.std():.4f}')\n\n# Print results in markdown table format\nresults_md = \"| Model               | RMSE (mean Â± std)        |\\n\"\nresults_md += \"|---------------------|--------------------------|\\n\"\nfor name, scores in cv_results.items():\n    results_md += f\"| {name:<20} | {scores.mean():.4f} Â± {scores.std():.4f} |\\n\"\nprint(results_md)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature importance\ndef plot_feature_importance(feature_importance, title):\n    fig = px.bar(\n        feature_importance,\n        x='Importance',\n        y='Feature',\n        orientation='h',\n        title=title\n    )\n    fig.update_layout(\n        xaxis_title='Importance',\n        yaxis_title='Feature',\n        font=dict(color='black'),  # Set font color to black\n        xaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n        yaxis=dict(showgrid=True, linecolor='black', linewidth=1, gridcolor='lightgray', gridwidth=0.5),\n        plot_bgcolor='rgba(255, 255, 255, 1)',  # White background\n        paper_bgcolor='rgba(255, 255, 255, 1)'\n    )\n    return fig\n\n# Train the models again to extract feature importance\nrf.fit(X_train, y_train)\ngbr.fit(X_train, y_train)\n\n# Get feature importances\nrf_importances = rf.feature_importances_\ngbr_importances = gbr.feature_importances_\n\n# Get feature names\nfeature_names = X.columns\n\n# Create a DataFrame for feature importances\nrf_features = pd.DataFrame({'Feature': feature_names, 'Importance': rf_importances})\ngbr_features = pd.DataFrame({'Feature': feature_names, 'Importance': gbr_importances})\n\n# Sort the DataFrame\nrf_features = rf_features.sort_values(by='Importance', ascending=False).head(20)\ngbr_features = gbr_features.sort_values(by='Importance', ascending=False).head(20)\n\n# Plot Random Forest Feature Importances\nfig_rf = plot_feature_importance(rf_features, 'Random Forest Feature Importances')\nfig_rf.show()\n\n# Save the scatter plot as a static image\nfig_rf.write_image(\"rf_feature_importance.png\", engine=\"kaleido\")\n\n# (Optional: Display the image in the notebook)\ndisplay(Image(\"rf_feature_importance.png\"))\n\n# Plot Gradient Boosting Feature Importances\nfig_gbr = plot_feature_importance(gbr_features, 'Gradient Boosting Feature Importances')\nfig_gbr.show()\n\n# Save the scatter plot as a static image\nfig_gbr.write_image(\"gbr_feature_importance.png\", engine=\"kaleido\")\n\n# (Optional: Display the image in the notebook)\ndisplay(Image(\"gbr_feature_importance.png\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# This Notebbok is Under Construction ","metadata":{}},{"cell_type":"code","source":"# Assume Gradient Boosting Regressor is the best-performing model\nbest_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\nbest_model.fit(X_train, y_train)\n\n# Predict on the validation set\ny_pred_best = best_model.predict(X_val)\n\n# Calculate final RMSE\nfinal_rmse = np.sqrt(mean_squared_error(y_val, y_pred_best))\nprint(f'Final RMSE of the Best Model (Gradient Boosting Regressor): {final_rmse:.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}